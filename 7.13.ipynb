{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f41ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import face_recognition\n",
    "import glob\n",
    "from PIL import Image\n",
    "import sys\n",
    "from pylibfreenect2 import Freenect2, SyncMultiFrameListener\n",
    "from pylibfreenect2 import FrameType, Registration, Frame\n",
    "from pylibfreenect2 import createConsoleLogger, setGlobalLogger\n",
    "from pylibfreenect2 import LoggerLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236466ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packet pipeline: OpenGLPacketPipeline\n"
     ]
    }
   ],
   "source": [
    "LEFT_CAMERA = \"015001743347\".encode('utf-8')\n",
    "RIGHT_CAMERA = \"009747143547\".encode('utf-8')\n",
    "# kinect basic \n",
    "try:\n",
    "    from pylibfreenect2 import OpenGLPacketPipeline\n",
    "    pipeline = OpenGLPacketPipeline()\n",
    "except:\n",
    "    try:\n",
    "        from pylibfreenect2 import OpenCLPacketPipeline\n",
    "        pipeline = OpenCLPacketPipeline()\n",
    "    except:\n",
    "        from pylibfreenect2 import CpuPacketPipeline\n",
    "        pipeline = CpuPacketPipeline()\n",
    "print(\"Packet pipeline:\", type(pipeline).__name__)\n",
    "\n",
    "# Create and set logger\n",
    "logger = createConsoleLogger(LoggerLevel.Debug)\n",
    "setGlobalLogger(logger)\n",
    "\n",
    "fn = Freenect2()\n",
    "num_devices = fn.enumerateDevices()\n",
    "if num_devices == 0:\n",
    "    print(\"No device connected!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "device = fn.openDevice(RIGHT_CAMERA, pipeline=pipeline)\n",
    "\n",
    "listener = SyncMultiFrameListener(\n",
    "    FrameType.Color | FrameType.Ir | FrameType.Depth)\n",
    "\n",
    "# Register listeners\n",
    "device.setColorFrameListener(listener)\n",
    "device.setIrAndDepthFrameListener(listener)\n",
    "\n",
    "device.start()\n",
    "\n",
    "# NOTE: must be called after device.start()\n",
    "registration = Registration(device.getIrCameraParams(),\n",
    "                            device.getColorCameraParams())\n",
    "\n",
    "undistorted = Frame(512, 424, 4)\n",
    "registered = Frame(512, 424, 4)\n",
    "\n",
    "# Optinal parameters for registration\n",
    "# set True if you need\n",
    "need_bigdepth = False\n",
    "need_color_depth_map = False\n",
    "\n",
    "bigdepth = Frame(1920, 1082, 4) if need_bigdepth else None\n",
    "color_depth_map = np.zeros((424, 512),  np.int32).ravel() \\\n",
    "    if need_color_depth_map else None\n",
    "\n",
    "# set video container\n",
    "fourcc = cv.VideoWriter_fourcc(*'FMP4') \n",
    "videoRGB = cv.VideoWriter('videoRGB.mp4', fourcc, 12, (1920, 1080))\n",
    "videoIR = cv.VideoWriter('videoIR.mp4', fourcc, 12, (512, 424), False)\n",
    "videoDepth = cv.VideoWriter('videoDepth.mp4', fourcc, 12, (512, 424), False)\n",
    "\n",
    "t1 = []\n",
    "t2 = []\n",
    "t3 = []\n",
    "t4 = []\n",
    "previousTimestamp = 0\n",
    "fpsArr = []\n",
    "\n",
    "RECORD = False\n",
    "RGB_IMG_COUNTER = 0\n",
    "D_IMG_COUNTER = 0\n",
    "\n",
    "while True:\n",
    "    frames = listener.waitForNewFrame()\n",
    "\n",
    "    color = frames[\"color\"]\n",
    "    ir = frames[\"ir\"]\n",
    "    depth = frames[\"depth\"]\n",
    "\n",
    "    registration.apply(color, depth, undistorted, registered,\n",
    "                       bigdepth=bigdepth,\n",
    "                       color_depth_map=color_depth_map)\n",
    "    # NOTE for visualization:\n",
    "    # cv2.imshow without OpenGL backend seems to be quite slow to draw all\n",
    "    # things below. Try commenting out some imshow if you don't have a fast\n",
    "    # visualization backend.\n",
    "    np_ir = ir.asarray()\n",
    "    np_depth = depth.asarray()\n",
    "    np_color = color.asarray()\n",
    "    np_registered = registered.asarray(np.uint8)\n",
    "    \n",
    "    np_ir /= np_ir.max()\n",
    "    np_ir = np.sqrt(np_ir)\n",
    "    np_ir = np.array(Image.fromarray(256 * np_ir).convert('L'))\n",
    "    \n",
    "    np_depth /= np_depth.max()\n",
    "    np_depth = np.sqrt(np_depth)\n",
    "    np_depth = np.array(Image.fromarray(256 * np_depth).convert('L'))\n",
    "    \n",
    "    np_color = np_color[:,:,:3]\n",
    "    \n",
    "    cv.imshow(\"ir\", np_ir)\n",
    "    cv.imshow(\"depth\", np_depth)\n",
    "    cv.imshow(\"color\", np_color)\n",
    "    cv.imshow(\"registered\", np_registered)\n",
    "    \n",
    "    \n",
    "    if RECORD == True:\n",
    "        videoIR.write(np_ir)\n",
    "        videoRGB.write(np_color)\n",
    "        videoDepth.write(np_depth)\n",
    "\n",
    "    if need_bigdepth:\n",
    "        cv.imshow(\"bigdepth\", cv.resize(bigdepth.asarray(np.float32),\n",
    "                                          (int(1920 / 3), int(1082 / 3))))\n",
    "    if need_color_depth_map:\n",
    "        cv.imshow(\"color_depth_map\", color_depth_map.reshape(424, 512))\n",
    "\n",
    "    listener.release(frames)\n",
    "\n",
    "    key = cv.waitKey(delay=1)\n",
    "    if key == ord('s'):\n",
    "        cv.imwrite(f'calib_img_rgb{RGB_IMG_COUNTER}.jpg', np_color)\n",
    "        RGB_IMG_COUNTER+=1\n",
    "    if key == ord('d'):\n",
    "        cv.imwrite(f'calib_img_d{D_IMG_COUNTER}.png', np_ir)\n",
    "        D_IMG_COUNTER+=1\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "device.stop()\n",
    "device.close()\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "videoRGB.release()\n",
    "videoIR.release()\n",
    "videoDepth.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2707ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calib_img_rgb8.jpg\n",
      "calib_img_rgb9.jpg\n",
      "calib_img_rgb2.jpg\n",
      "calib_img_rgb3.jpg\n",
      "calib_img_rgb1.jpg\n",
      "calib_img_rgb0.jpg\n",
      "calib_img_rgb4.jpg\n",
      "calib_img_rgb5.jpg\n",
      "calib_img_rgb7.jpg\n",
      "calib_img_rgb6.jpg\n",
      "calib_img_rgb11.jpg\n",
      "calib_img_rgb10.jpg\n",
      "calib_img_rgb12.jpg\n",
      "calib_img_rgb13.jpg\n",
      "calib_img_d12.png\n",
      "calib_img_d13.png\n",
      "calib_img_d11.png\n",
      "calib_img_d10.png\n",
      "calib_img_d14.png\n",
      "calib_img_d3.png\n",
      "calib_img_d2.png\n",
      "calib_img_d0.png\n",
      "calib_img_d1.png\n",
      "calib_img_d5.png\n",
      "calib_img_d4.png\n",
      "calib_img_d6.png\n",
      "calib_img_d7.png\n",
      "calib_img_d9.png\n",
      "calib_img_d8.png\n"
     ]
    }
   ],
   "source": [
    "# calib img\n",
    "CHECKERBOARD = (9,6)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((1, CHECKERBOARD[0]* CHECKERBOARD[1],3), np.float32)\n",
    "objp[0, :, :2] = np.mgrid[0:CHECKERBOARD[0],0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "# rgb camera calib\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('calib_img_rgb*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "    if ret == True:\n",
    "        print(fname)\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "camera_file = {\"ret\": ret, \"mtx\": mtx, \"dist\": dist, \"rvecs\": rvecs, \"tvecs\": tvecs}\n",
    "\n",
    "# depth camera calib   \n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "ir_images = glob.glob('calib_img_d*.png')\n",
    "\n",
    "for fname in ir_images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "    if ret == True:\n",
    "        print(fname)\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "             \n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "depth_camera_file = {\"ret\": ret, \"mtx\": mtx, \"dist\": dist, \"rvecs\": rvecs, \"tvecs\": tvecs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6450a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5ab7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort kinect img\n",
    "img = cv.imread('calib_img_9.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7b91381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 44.46178636775677\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs, tvecs, mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9945a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packet pipeline: OpenGLPacketPipeline\n"
     ]
    }
   ],
   "source": [
    "# live checkerboard cube render with kinect\n",
    "\n",
    "#checkerboard axis or cube to corner\n",
    "def drawHelper(f):\n",
    "    x = int(f * scale_factor)\n",
    "    if x > 100000:\n",
    "        x = 100000\n",
    "    if x < 0:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "def draw(img, corners, imgpts):\n",
    "    if drawType:\n",
    "        return drawCube(img, corners, imgpts)\n",
    "    else:\n",
    "        return drawAxis(img, corners, imgpts)\n",
    "\n",
    "def drawAxis(img, corners, imgpts):\n",
    "    corner = tuple(map(drawHelper, corners[0].ravel()))\n",
    "    img = cv.line(img, corner, tuple(map(drawHelper, imgpts[0].ravel())), (255,0,0), 5)\n",
    "    img = cv.line(img, corner, tuple(map(drawHelper, imgpts[1].ravel())), (0,255,0), 5)\n",
    "    img = cv.line(img, corner, tuple(map(drawHelper, imgpts[2].ravel())), (0,0,255), 5)\n",
    "    return img\n",
    "\n",
    "def drawCube(img, corners, imgpts):\n",
    "    imgpts = np.array([[drawHelper(f) for f in p] for p in np.int32(imgpts).reshape(-1,2)])\n",
    "    # draw ground floor in green\n",
    "    img = cv.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "    # draw top layer in red color\n",
    "    img = cv.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "    return img\n",
    "\n",
    "        \n",
    "CHECKERBOARD = (9,6)\n",
    "process_this_frame = 0\n",
    "screen_scale_factor = 1\n",
    "scale_factor = 1\n",
    "drawType = 1\n",
    "saved_corners2=[[[]]]\n",
    "saved_imgpts = [[[]]]\n",
    "saved_ir_corners2 = [[[]]]\n",
    "saved_ir_imgpts = [[[]]]\n",
    "\n",
    "axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "\n",
    "if drawType:\n",
    "    axis = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0],\n",
    "                   [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])\n",
    "\n",
    "    \n",
    "# kinect init\n",
    "try:\n",
    "    from pylibfreenect2 import OpenGLPacketPipeline\n",
    "    pipeline = OpenGLPacketPipeline()\n",
    "except:\n",
    "    try:\n",
    "        from pylibfreenect2 import OpenCLPacketPipeline\n",
    "        pipeline = OpenCLPacketPipeline()\n",
    "    except:\n",
    "        from pylibfreenect2 import CpuPacketPipeline\n",
    "        pipeline = CpuPacketPipeline()\n",
    "print(\"Packet pipeline:\", type(pipeline).__name__)\n",
    "\n",
    "fn = Freenect2()\n",
    "num_devices = fn.enumerateDevices()\n",
    "if num_devices == 0:\n",
    "    print(\"No device connected!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "device = fn.openDevice(LEFT_CAMERA, pipeline=pipeline)\n",
    "\n",
    "listener = SyncMultiFrameListener(\n",
    "    FrameType.Color | FrameType.Ir)\n",
    "\n",
    "# Register listeners\n",
    "device.setColorFrameListener(listener)\n",
    "device.setIrAndDepthFrameListener(listener)\n",
    "\n",
    "device.start()\n",
    "\n",
    "while True:\n",
    "    frames = listener.waitForNewFrame()\n",
    "    color = frames[\"color\"]\n",
    "    ir = frames[\"ir\"]\n",
    "    \n",
    "    np_color = color.asarray()\n",
    "    np_color = np_color[:,:,:3]\n",
    "    frame = np_color\n",
    "    \n",
    "    ir = ir.asarray()\n",
    "    ir /= ir.max()\n",
    "    ir = np.sqrt(ir)\n",
    "    np_ir = np.array(Image.fromarray(256 * ir).convert('L'))\n",
    "    ir_frame = np_ir\n",
    "\n",
    "    frame = cv.resize(frame, (frame.shape[1]//screen_scale_factor, frame.shape[0]//screen_scale_factor), interpolation = cv.INTER_CUBIC)\n",
    "    process_this_frame-=1\n",
    "    \n",
    "    if process_this_frame <= 0:\n",
    "        process_this_frame = 5\n",
    "        small_frame = cv.resize(frame, (0, 0), fx=1 / scale_factor, fy=1 / scale_factor)\n",
    "        gray = cv.cvtColor(small_frame,cv.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD,None)\n",
    "        \n",
    "        small_ir_frame = cv.resize(ir_frame, (0, 0), fx=1 / scale_factor, fy=1 / scale_factor)\n",
    "        ir_gray = small_ir_frame\n",
    "        ir_ret, ir_corners = cv.findChessboardCorners(ir_gray, CHECKERBOARD,None)\n",
    "\n",
    "        if ret:\n",
    "            corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            ret,rvecs, tvecs = cv.solvePnP(objp, corners2, camera_file[\"mtx\"], camera_file[\"dist\"])\n",
    "            imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, camera_file[\"mtx\"], camera_file[\"dist\"])\n",
    "            saved_corners2 = corners2\n",
    "            saved_imgpts = imgpts\n",
    "        \n",
    "        if ir_ret:\n",
    "            corners2 = cv.cornerSubPix(ir_gray,ir_corners, (11,11), (-1,-1), criteria)\n",
    "            ret,rvecs, tvecs = cv.solvePnP(objp, corners2, depth_camera_file[\"mtx\"], depth_camera_file[\"dist\"])\n",
    "            imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, depth_camera_file[\"mtx\"], depth_camera_file[\"dist\"])\n",
    "            saved_ir_corners2 = corners2\n",
    "            saved_ir_imgpts = imgpts\n",
    "            \n",
    "    listener.release(frames)\n",
    "    if len(saved_corners2) > 1:\n",
    "        frame = draw(frame,saved_corners2,saved_imgpts)\n",
    "    if len(saved_ir_corners2) > 1:\n",
    "        ir_frame = draw(ir_frame,saved_ir_corners2,saved_ir_imgpts)\n",
    "    cv.imshow(\"Live\", frame)\n",
    "    cv.imshow(\"IR\", ir_frame)\n",
    "    if cv.waitKey(20) & 0xFF==ord('q'):\n",
    "        break \n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "device.stop()\n",
    "device.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "686516ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in glob.glob('*.jpg'):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD,None)\n",
    "    if ret == True:\n",
    "        corners2 = cv.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        # Find the rotation and translation vectors.\n",
    "        ret,rvecs, tvecs = cv.solvePnP(objp, corners2, camera_file[\"mtx\"], camera_file[\"dist\"])\n",
    "        # project 3D points to image plane\n",
    "        imgpts, jac = cv.projectPoints(axis, rvecs, tvecs, camera_file[\"mtx\"], camera_file[\"dist\"])\n",
    "        img = draw(img,corners2,imgpts)\n",
    "        cv.imshow('img',img)\n",
    "        k = cv.waitKey(0) & 0xFF\n",
    "        if k == ord('s'):\n",
    "            cv.imwrite(fname+'.png', img)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "781a24d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33570580e+03, 0.00000000e+00, 6.00272754e+02],\n",
       "       [0.00000000e+00, 1.32726396e+03, 4.45745390e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968c314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
